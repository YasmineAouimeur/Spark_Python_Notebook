{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20200409151707-0000\nKERNEL_ID = 3be29ba1-b754-4ddc-be6d-6d4088db23ad\n"
                }
            ],
            "source": "## Use data of a production machine, where each row contains informations about a particular part\n## Ceate a data point\n## In this case, instead of \"asperity\" we will have a binary attribute \"Broken\" to say if the part is broken with aspirity>1 or not with asperity<1, \ndp1 = {'partno': 100, 'maxtemp': 35, 'mintemp': 35, 'maxvibration': 12, 'Broken': 0}\ndp2 = {'partno': 101, 'maxtemp': 46, 'mintemp': 35, 'maxvibration': 21, 'Broken': 0}\ndp3 = {'partno': 130, 'maxtemp': 56, 'mintemp': 46, 'maxvibration': 3412, 'Broken': 1}\ndp4 = {'partno': 131, 'maxtemp': 58, 'mintemp': 48, 'maxvibration': 3542, 'Broken': 1}"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "## We will change this regression data set into a binary classification data set. Then our rule gets more simple and also more precise.\ndef predict(dp):\n    if dp['maxvibration']>100:\n        return 1\n    else:\n        return 0"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0"
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "predict(dp1)"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "## changed our linear regression model to an regression one.\n## In order to achieve this, just add a sigmoid computation step to our site\nimport math\n\ndef sigmoid(x):\n    return 1/(1+math.exp(-x))"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": "## Logistic regression is to create a binary relationship between filds by using fild numbers and a rate 'W' \nw1 = 0.33\nw2 = 0\nw3 = 0\nw4 = 13/3412\n\ndef mlpredict(dp):\n    return 0 if sigmoid(w1+w2*dp['maxtemp']+w3*dp['mintemp']+w4*dp['maxvibration'])<0.7 else 1"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0"
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "mlpredict(dp1)"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[Row(x=22, y=49, z=35, class='Brush_teeth', source='Accelerometer-2011-04-11-13-28-18-brush_teeth-f1.txt'),\n Row(x=22, y=49, z=35, class='Brush_teeth', source='Accelerometer-2011-04-11-13-28-18-brush_teeth-f1.txt'),\n Row(x=22, y=52, z=35, class='Brush_teeth', source='Accelerometer-2011-04-11-13-28-18-brush_teeth-f1.txt'),\n Row(x=22, y=52, z=35, class='Brush_teeth', source='Accelerometer-2011-04-11-13-28-18-brush_teeth-f1.txt'),\n Row(x=21, y=52, z=34, class='Brush_teeth', source='Accelerometer-2011-04-11-13-28-18-brush_teeth-f1.txt')]"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": "df = df_data_1"
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": "## We split the dataset to 0.8 train data and 0.2 test data\nsplits = df.randomSplit([0.8,0.2])\ndf_train = splits[0]\ndf_test = splits[1]"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Normalizer\nfrom pyspark.ml.linalg import Vectors\n\nindexer = StringIndexer(inputCol='class', outputCol='label')\nassembler = VectorAssembler(inputCols=['x','y','z'], outputCol='features')\nnormalizer = Normalizer(inputCol='features', outputCol='features_norm')"
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml.classification import LogisticRegression"
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": "Lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)"
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages=[indexer,assembler,normalizer,Lr])\nmodel = pipeline.fit(df_train)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [],
            "source": "## Compute predictions\nprediction = model.transform(df_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+---+---+---+--------------+--------------------+-----+---------------+--------------------+--------------------+--------------------+----------+\n|  x|  y|  z|         class|              source|label|       features|       features_norm|       rawPrediction|         probability|prediction|\n+---+---+---+--------------+--------------------+-----+---------------+--------------------+--------------------+--------------------+----------+\n|  0| 10| 28|     Getup_bed|Accelerometer-201...|  0.0|[0.0,10.0,28.0]|[0.0,0.3363363969...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 11| 38| Sitdown_chair|Accelerometer-201...|  7.0|[0.0,11.0,38.0]|[0.0,0.2780580765...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 12| 39| Sitdown_chair|Accelerometer-201...|  7.0|[0.0,12.0,39.0]|[0.0,0.2940858488...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 16| 31|     Getup_bed|Accelerometer-201...|  0.0|[0.0,16.0,31.0]|[0.0,0.4586429197...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 17| 36|   Brush_teeth|Accelerometer-201...|  5.0|[0.0,17.0,36.0]|[0.0,0.4270063054...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 23| 36|   Brush_teeth|Accelerometer-201...|  5.0|[0.0,23.0,36.0]|[0.0,0.5383892771...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 25| 30|   Brush_teeth|Accelerometer-201...|  5.0|[0.0,25.0,30.0]|[0.0,0.6401843996...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 25| 40|   Brush_teeth|Accelerometer-201...|  5.0|[0.0,25.0,40.0]|[0.0,0.5299989400...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 26| 15|  Climb_stairs|Accelerometer-201...|  3.0|[0.0,26.0,15.0]|[0.0,0.8661855860...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 26| 42|   Brush_teeth|Accelerometer-201...|  5.0|[0.0,26.0,42.0]|[0.0,0.5263546146...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 27| 31| Sitdown_chair|Accelerometer-201...|  7.0|[0.0,27.0,31.0]|[0.0,0.6567807448...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 27| 37|   Brush_teeth|Accelerometer-201...|  5.0|[0.0,27.0,37.0]|[0.0,0.5894690700...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 27| 39|   Brush_teeth|Accelerometer-201...|  5.0|[0.0,27.0,39.0]|[0.0,0.5692099788...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 28| 48|   Brush_teeth|Accelerometer-201...|  5.0|[0.0,28.0,48.0]|[0.0,0.5038710255...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 29| 25|     Getup_bed|Accelerometer-201...|  0.0|[0.0,29.0,25.0]|[0.0,0.7574099616...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 29| 32|Descend_stairs|Accelerometer-201...|  9.0|[0.0,29.0,32.0]|[0.0,0.6715194247...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 29| 37|   Brush_teeth|Accelerometer-201...|  5.0|[0.0,29.0,37.0]|[0.0,0.6168816632...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 29| 38|   Brush_teeth|Accelerometer-201...|  5.0|[0.0,29.0,38.0]|[0.0,0.6066733193...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 29| 43|   Brush_teeth|Accelerometer-201...|  5.0|[0.0,29.0,43.0]|[0.0,0.5591416682...|[0.64772850969516...|[0.12888508466137...|       0.0|\n|  0| 29| 46|   Brush_teeth|Accelerometer-201...|  5.0|[0.0,29.0,46.0]|[0.0,0.5333009233...|[0.64772850969516...|[0.12888508466137...|       0.0|\n+---+---+---+--------------+--------------------+-----+---------------+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n"
                }
            ],
            "source": "prediction.show()"
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [],
            "source": "eval = MulticlassClassificationEvaluator().setMetricName('accuracy').setLabelCol('label').setPredictionCol('prediction')"
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.12888490693154522"
                    },
                    "execution_count": 47,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "eval.evaluate(prediction)"
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.130867267640659"
                    },
                    "execution_count": 49,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "## So now let's do the test using the test data. So basically, we do the same. So we feed the df_test\nmodel = pipeline.fit(df_test)\n## And now we compute our predictions using the model.transform(df_test).\npredictionTest = model.transform(df_test)\n\n##And we can re-use our evaluator. And we hopefully should see a similar result.\neval.evaluate(predictionTest)\n\n## Okay, cool, it's nearly 13% as well. And that's actually cool, if we get nearly the same number but a slightly lower number, \n## that means everything is all right.\n\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark",
            "language": "python3",
            "name": "python36"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}